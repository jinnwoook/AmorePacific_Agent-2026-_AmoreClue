"""
LangChain + LangGraph ê¸°ë°˜ Multi-Agent ì›Œí¬í”Œë¡œìš°
ì œí’ˆ ì„¤ëª… ë¶„ì„ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ íš¨ê³¼ ë§¤í•‘ â†’ ì¡°í•© ë¶„ì„ â†’ íŠ¸ë Œë“œ ì§‘ê³„ â†’ SNS í”Œë«í¼ ë¶„ì„
"""

from langgraph.graph import StateGraph, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage
from typing import TypedDict, List, Dict, Any
from pymongo import MongoClient
from datetime import datetime, timedelta
import json
import os
from dotenv import load_dotenv

load_dotenv()

# MongoDB ì—°ê²°
mongodb_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
mongodb_db = os.getenv("MONGODB_DATABASE", "amore")
client = MongoClient(mongodb_uri)
db = client[mongodb_db]

# Gemini API í‚¤ (amore í´ë”ì—ì„œ ê°€ì ¸ì˜¨ ê°’)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_GEMINI_API_KEY_HERE")

# LLM ì´ˆê¸°í™” (Gemini ì‚¬ìš©)
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0.1,
    google_api_key=GEMINI_API_KEY
)

llm_advanced = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    temperature=0.2,
    google_api_key=GEMINI_API_KEY
)


# State ì •ì˜
class WorkflowState(TypedDict):
    product_descriptions: List[Dict[str, Any]]  # [{productId, description, salesRank, ...}]
    extracted_keywords: Dict[str, Dict[str, List[str]]]  # {productId: {ingredients: [], formulas: [], effects: [], mood: []}}
    mapped_effects: Dict[str, Dict[str, List[str]]]  # {productId: {keyword: [effects]}}
    combinations: List[Dict[str, Any]]  # [{combination, ingredients, formulas, effects, avgRank, ...}]
    trends: List[Dict[str, Any]]  # [{combination, score, category, signals, ...}]
    sns_stats: Dict[str, List[Dict[str, Any]]]  # {platform: [{keyword, value, change, type}]}


# Agent 1: í‚¤ì›Œë“œ ì¶”ì¶œ Agent
def extract_keywords_node(state: WorkflowState) -> WorkflowState:
    """ì œí’ˆ ì„¤ëª…ì—ì„œ ì„±ë¶„, ì œí˜•, íš¨ê³¼, Mood í‚¤ì›Œë“œ ì¶”ì¶œ"""
    print("ğŸ” Agent 1: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘...")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are an expert in cosmetic product analysis.
        Extract keywords from product descriptions and classify them into 4 categories:
        - ingredients: cosmetic ingredients (e.g., ë ˆí‹°ë†€, íˆì•Œë£¨ë¡ ì‚°, ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ)
        - formulas: product forms/textures (e.g., ì•°í”Œ, í¬ë¦¼, ì„¸ëŸ¼, í† ë„ˆ, íŒ¨ë“œ)
        - effects: effects/benefits (e.g., ëª¨ê³µ ì¼€ì–´, ì¥ë²½ ê°•í™”, ë¯¸ë°±, ì§„ì •)
        - mood: visual/mood elements (e.g., ë¯¸ë‹ˆì–´ì²˜, ë§¤íŠ¸ í…ìŠ¤ì²˜, ëŸ­ì…”ë¦¬, ê·¸ë¦½)
        
        Return JSON format:
        {{
            "ingredients": ["ingredient1", "ingredient2"],
            "formulas": ["formula1", "formula2"],
            "effects": ["effect1", "effect2"],
            "mood": ["mood1", "mood2"]
        }}
        
        If a category has no keywords, return empty array []."""),
        ("user", "Product description: {description}")
    ])
    
    extracted_keywords = {}
    
    for product in state["product_descriptions"]:
        product_id = product["productId"]
        description = product.get("description", "")
        
        if not description:
            extracted_keywords[product_id] = {
                "ingredients": [],
                "formulas": [],
                "effects": [],
                "mood": []
            }
            continue
        
        try:
            chain = prompt | llm
            response = chain.invoke({"description": description})
            
            # JSON íŒŒì‹±
            content = response.content
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()
            
            keywords = json.loads(content)
            extracted_keywords[product_id] = {
                "ingredients": keywords.get("ingredients", []),
                "formulas": keywords.get("formulas", []),
                "effects": keywords.get("effects", []),
                "mood": keywords.get("mood", [])
            }
            
            print(f"  âœ“ {product_id}: {len(keywords.get('ingredients', []))} ì„±ë¶„, {len(keywords.get('formulas', []))} ì œí˜•, {len(keywords.get('effects', []))} íš¨ê³¼, {len(keywords.get('mood', []))} Mood")
            
        except Exception as e:
            print(f"  âœ— {product_id} ì˜¤ë¥˜: {e}")
            extracted_keywords[product_id] = {
                "ingredients": [],
                "formulas": [],
                "effects": [],
                "mood": []
            }
    
    state["extracted_keywords"] = extracted_keywords
    print(f"âœ… Agent 1 ì™„ë£Œ: {len(extracted_keywords)}ê°œ ì œí’ˆ ì²˜ë¦¬")
    return state


# Agent 2: íš¨ê³¼ ë§¤í•‘ Agent
def map_effects_node(state: WorkflowState) -> WorkflowState:
    """ê° í‚¤ì›Œë“œë³„ ê´€ë ¨ íš¨ê³¼ ì¶”ì¶œ"""
    print("ğŸ” Agent 2: íš¨ê³¼ ë§¤í•‘ ì‹œì‘...")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """You are an expert in cosmetic effects analysis.
        For each keyword, extract related effects mentioned in reviews or product descriptions.
        
        Return JSON format:
        {{
            "keyword1": ["effect1", "effect2"],
            "keyword2": ["effect3", "effect4"]
        }}
        
        Focus on cosmetic effects and benefits."""),
        ("user", "Keywords: {keywords}\n\nReviews: {reviews}")
    ])
    
    mapped_effects = {}
    
    for product_id, keywords_dict in state["extracted_keywords"].items():
        # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = (
            keywords_dict.get("ingredients", []) +
            keywords_dict.get("formulas", []) +
            keywords_dict.get("effects", []) +
            keywords_dict.get("mood", [])
        )
        
        if not all_keywords:
            mapped_effects[product_id] = {}
            continue
        
        # í•´ë‹¹ ì œí’ˆì˜ ë¦¬ë·° ì¡°íšŒ
        product = next((p for p in state["product_descriptions"] if p["productId"] == product_id), None)
        if not product:
            mapped_effects[product_id] = {}
            continue
        
        reviews = db.raw_reviews.find({
            "productId": product_id
        }).limit(20)
        
        review_texts = "\n".join([r.get("content", "") for r in reviews])
        
        try:
            chain = prompt | llm_advanced
            response = chain.invoke({
                "keywords": ", ".join(all_keywords),
                "reviews": review_texts[:2000]  # í† í° ì œí•œ
            })
            
            content = response.content
            if content.startswith("```json"):
                content = content.replace("```json", "").replace("```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()
            
            effects_map = json.loads(content)
            mapped_effects[product_id] = effects_map
            
            print(f"  âœ“ {product_id}: {len(effects_map)}ê°œ í‚¤ì›Œë“œ íš¨ê³¼ ë§¤í•‘")
            
        except Exception as e:
            print(f"  âœ— {product_id} ì˜¤ë¥˜: {e}")
            mapped_effects[product_id] = {}
    
    state["mapped_effects"] = mapped_effects
    print(f"âœ… Agent 2 ì™„ë£Œ")
    return state


# Agent 3: ì¡°í•© ë¶„ì„ Agent
def analyze_combinations_node(state: WorkflowState) -> WorkflowState:
    """ê°€ì¥ ì˜ íŒ”ë¦¬ëŠ” ì¡°í•© ë¶„ì„ (ì„±ë¶„ + ì œí˜• + íš¨ê³¼)"""
    print("ğŸ” Agent 3: ì¡°í•© ë¶„ì„ ì‹œì‘...")
    
    # ì¡°í•©ë³„ ì œí’ˆ ê·¸ë£¹í™”
    combination_map = {}
    
    for product in state["product_descriptions"]:
        product_id = product["productId"]
        keywords = state["extracted_keywords"].get(product_id, {})
        
        ingredients = keywords.get("ingredients", [])
        formulas = keywords.get("formulas", [])
        effects = keywords.get("effects", [])
        
        # ì¡°í•© ìƒì„± (ìµœëŒ€ 3ê°œì”©)
        if ingredients and formulas and effects:
            # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì¡°í•© ì„ íƒ
            top_ingredient = ingredients[0] if ingredients else ""
            top_formula = formulas[0] if formulas else ""
            top_effect = effects[0] if effects else ""
            
            combination_key = f"{top_ingredient} + {top_formula} + {top_effect}"
            
            if combination_key not in combination_map:
                combination_map[combination_key] = {
                    "combination": combination_key,
                    "ingredients": ingredients,
                    "formulas": formulas,
                    "effects": effects,
                    "products": [],
                    "ranks": []
                }
            
            combination_map[combination_key]["products"].append(product)
            if product.get("salesRank"):
                combination_map[combination_key]["ranks"].append(product["salesRank"])
    
    # ì¡°í•©ë³„ í†µê³„ ê³„ì‚°
    combinations = []
    for combo_key, combo_data in combination_map.items():
        ranks = combo_data["ranks"]
        avg_rank = sum(ranks) / len(ranks) if ranks else 1000
        
        combinations.append({
            "combination": combo_key,
            "ingredients": list(set(combo_data["ingredients"])),
            "formulas": list(set(combo_data["formulas"])),
            "effects": list(set(combo_data["effects"])),
            "avgRank": avg_rank,
            "productCount": len(combo_data["products"]),
            "totalSales": sum(p.get("salesVolume", 0) for p in combo_data["products"]),
            "synergyScore": calculate_synergy_score(combo_data)
        })
    
    # ë­í‚¹ ìˆœìœ¼ë¡œ ì •ë ¬
    combinations.sort(key=lambda x: x["avgRank"])
    
    state["combinations"] = combinations
    print(f"âœ… Agent 3 ì™„ë£Œ: {len(combinations)}ê°œ ì¡°í•© ë¶„ì„")
    return state


# Agent 4: íŠ¸ë Œë“œ ì§‘ê³„ Agent
def aggregate_trends_node(state: WorkflowState) -> WorkflowState:
    """íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚° ë° ë¶„ë¥˜"""
    print("ğŸ” Agent 4: íŠ¸ë Œë“œ ì§‘ê³„ ì‹œì‘...")
    
    trends = []
    
    for combo in state["combinations"]:
        # ì‹ í˜¸ ë°ì´í„° ê³„ì‚°
        signals = calculate_signals(combo, state)
        
        # íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚°
        score = calculate_trend_score(combo, signals)
        
        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        category = classify_trend_category(score, combo, signals)
        
        trends.append({
            "combination": combo["combination"],
            "ingredients": combo["ingredients"],
            "formulas": combo["formulas"],
            "effects": combo["effects"],
            "avgRank": combo["avgRank"],
            "productCount": combo["productCount"],
            "score": score,
            "category": category,  # Early, Growing, Actionable
            "signals": signals
        })
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    trends.sort(key=lambda x: x["score"], reverse=True)
    
    state["trends"] = trends
    print(f"âœ… Agent 4 ì™„ë£Œ: {len(trends)}ê°œ íŠ¸ë Œë“œ ìƒì„±")
    return state


# Agent 5: SNS í”Œë«í¼ ë¶„ì„ Agent
def analyze_sns_platforms_node(state: WorkflowState) -> WorkflowState:
    """SNS í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„ ë¶„ì„"""
    print("ğŸ” Agent 5: SNS í”Œë«í¼ ë¶„ì„ ì‹œì‘...")
    
    platforms = ["Instagram", "TikTok", "YouTube", "Amazon", "Shopee", "Cosme"]
    sns_stats = {}
    
    # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
    all_keywords = {}
    for product_id, keywords_dict in state["extracted_keywords"].items():
        for category, keywords in keywords_dict.items():
            for keyword in keywords:
                if keyword not in all_keywords:
                    all_keywords[keyword] = {
                        "keyword": keyword,
                        "type": category,
                        "counts": {}
                    }
    
    # í”Œë«í¼ë³„ í‚¤ì›Œë“œ ì–¸ê¸‰ ìˆ˜ ì§‘ê³„
    end_date = datetime.now()
    start_date = end_date - timedelta(weeks=8)
    
    for platform in platforms:
        platform_keywords = []
        
        for keyword, keyword_data in all_keywords.items():
            # SNS ê²Œì‹œë¬¼ì—ì„œ í‚¤ì›Œë“œ ì–¸ê¸‰ ìˆ˜ ì¡°íšŒ
            count = db.raw_sns_posts.count_documents({
                "platform": platform,
                "postedAt": {"$gte": start_date, "$lte": end_date},
                "$or": [
                    {"content": {"$regex": keyword, "$options": "i"}},
                    {"hashtags": keyword}
                ]
            })
            
            if count > 0:
                platform_keywords.append({
                    "keyword": keyword,
                    "value": min(100, count / 10),  # 1000ê°œ = 100ì 
                    "change": 0,  # ì „ì£¼ ëŒ€ë¹„ (ì¶”í›„ ê³„ì‚°)
                    "type": keyword_data["type"]
                })
        
        # ê°’ ìˆœìœ¼ë¡œ ì •ë ¬
        platform_keywords.sort(key=lambda x: x["value"], reverse=True)
        sns_stats[platform] = platform_keywords[:10]  # ìƒìœ„ 10ê°œ
    
    state["sns_stats"] = sns_stats
    print(f"âœ… Agent 5 ì™„ë£Œ: {len(platforms)}ê°œ í”Œë«í¼ ë¶„ì„")
    return state


# Helper í•¨ìˆ˜ë“¤

def calculate_synergy_score(combo_data: Dict) -> float:
    """ì¡°í•© ì‹œë„ˆì§€ ì ìˆ˜ ê³„ì‚°"""
    # ì œí’ˆ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡, ë­í‚¹ì´ ì¢‹ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
    product_count = len(combo_data["products"])
    avg_rank = sum(combo_data["ranks"]) / len(combo_data["ranks"]) if combo_data["ranks"] else 1000
    
    rank_score = max(0, 1 - (avg_rank - 1) / 1000)  # 1ìœ„ = 1.0, 1000ìœ„ = 0.0
    count_score = min(1, product_count / 20)  # 20ê°œ ì´ìƒ = 1.0
    
    return (rank_score * 0.7 + count_score * 0.3)


def calculate_signals(combo: Dict, state: WorkflowState) -> Dict[str, float]:
    """SNS, Retail, Review ì‹ í˜¸ ê³„ì‚°"""
    # ê°„ë‹¨í™”: ì‹¤ì œë¡œëŠ” DBì—ì„œ ì§‘ê³„
    return {
        "SNS": 85.0,
        "Retail": 90.0,
        "Review": 88.0
    }


def calculate_trend_score(combo: Dict, signals: Dict[str, float]) -> float:
    """íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚°"""
    rank_score = max(0, 100 - (combo["avgRank"] - 1) * 0.2)
    signal_score = (signals["SNS"] + signals["Retail"] + signals["Review"]) / 3
    synergy_score = combo.get("synergyScore", 0.5) * 100
    
    return rank_score * 0.4 + signal_score * 0.4 + synergy_score * 0.2


def classify_trend_category(score: float, combo: Dict, signals: Dict[str, float]) -> str:
    """íŠ¸ë Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    if score >= 80 and combo["avgRank"] <= 20:
        return "Actionable"
    elif score >= 60 and combo["avgRank"] <= 50:
        return "Growing"
    else:
        return "Early"


# ì›Œí¬í”Œë¡œìš° êµ¬ì„±
def create_workflow():
    workflow = StateGraph(WorkflowState)
    
    # Node ì¶”ê°€
    workflow.add_node("extract_keywords", extract_keywords_node)
    workflow.add_node("map_effects", map_effects_node)
    workflow.add_node("analyze_combinations", analyze_combinations_node)
    workflow.add_node("aggregate_trends", aggregate_trends_node)
    workflow.add_node("analyze_sns_platforms", analyze_sns_platforms_node)
    
    # Edge ì •ì˜
    workflow.set_entry_point("extract_keywords")
    workflow.add_edge("extract_keywords", "map_effects")
    workflow.add_edge("map_effects", "analyze_combinations")
    workflow.add_edge("analyze_combinations", "aggregate_trends")
    workflow.add_edge("aggregate_trends", "analyze_sns_platforms")
    workflow.add_edge("analyze_sns_platforms", END)
    
    return workflow.compile()


# DB ì €ì¥ í•¨ìˆ˜
def save_to_db(state: WorkflowState):
    """ì›Œí¬í”Œë¡œìš° ê²°ê³¼ë¥¼ DBì— ì €ì¥"""
    print("ğŸ’¾ DB ì €ì¥ ì‹œì‘...")
    
    # 1. processed_keywords ì €ì¥
    for product_id, keywords_dict in state["extracted_keywords"].items():
        for category, keywords in keywords_dict.items():
            for keyword in keywords:
                effects = state["mapped_effects"].get(product_id, {}).get(keyword, [])
                
                db.processed_keywords.insert_one({
                    "keyword": keyword,
                    "keywordType": category,
                    "sourceType": "product_description",
                    "sourceId": product_id,
                    "effects": effects,
                    "extractedAt": datetime.now(),
                    "processedAt": datetime.now()
                })
    
    # 2. trends ì €ì¥
    for trend in state["trends"]:
        db.trends.replace_one(
            {"combination": trend["combination"]},
            {
                **trend,
                "calculatedAt": datetime.now(),
                "updatedAt": datetime.now()
            },
            upsert=True
        )
    
    # 3. sns_platform_stats ì €ì¥
    for platform, keywords in state["sns_stats"].items():
        db.sns_platform_stats.insert_one({
            "platform": platform,
            "country": "usa",  # ë™ì ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥
            "keywords": keywords,
            "date": datetime.now(),
            "calculatedAt": datetime.now()
        })
    
    print("âœ… DB ì €ì¥ ì™„ë£Œ")


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run_workflow(country="usa", category="Skincare", weeks=8):
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    print(f"ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {country}/{category} ({weeks}ì£¼)")
    
    # ìµœê·¼ 8ì£¼ ë°ì´í„° ì¡°íšŒ
    end_date = datetime.now()
    start_date = end_date - timedelta(weeks=weeks)
    
    products = list(db.raw_retail_sales.find({
        "country": country,
        "category": category,
        "date": {"$gte": start_date, "$lte": end_date}
    }))
    
    print(f"ğŸ“¦ {len(products)}ê°œ ì œí’ˆ ë°œê²¬")
    
    # ì´ˆê¸° State ìƒì„±
    initial_state: WorkflowState = {
        "product_descriptions": [
            {
                "productId": p["productId"],
                "description": p.get("description", ""),
                "salesRank": p.get("salesRank", 1000),
                "salesVolume": p.get("salesVolume", 0),
                "brand": p.get("brand", ""),
                "productName": p.get("productName", "")
            }
            for p in products
        ],
        "extracted_keywords": {},
        "mapped_effects": {},
        "combinations": [],
        "trends": [],
        "sns_stats": {}
    }
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    app = create_workflow()
    final_state = app.invoke(initial_state)
    
    # DB ì €ì¥
    save_to_db(final_state)
    
    print("ğŸ‰ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
    return final_state


if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    country = sys.argv[1] if len(sys.argv) > 1 else "usa"
    category = sys.argv[2] if len(sys.argv) > 2 else "Skincare"
    weeks = int(sys.argv[3]) if len(sys.argv) > 3 else 8
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = run_workflow(country=country, category=category, weeks=weeks)
    print(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(f"  - ì¶”ì¶œëœ í‚¤ì›Œë“œ: {len(result['extracted_keywords'])}ê°œ ì œí’ˆ")
    print(f"  - ë¶„ì„ëœ ì¡°í•©: {len(result['combinations'])}ê°œ")
    print(f"  - íŠ¸ë Œë“œ: {len(result['trends'])}ê°œ")
    print(f"  - SNS í”Œë«í¼: {len(result['sns_stats'])}ê°œ")


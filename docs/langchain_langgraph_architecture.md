# LangChain + LangGraph ê¸°ë°˜ Multi-Agent ì›Œí¬í”Œë¡œìš°

## ğŸ¯ ëª©í‘œ

1. **ì œí’ˆ ì„¤ëª… ë¶„ì„**: ì„±ë¶„, ì œí˜•, íš¨ê³¼, Mood í‚¤ì›Œë“œ ì¶”ì¶œ
2. **íš¨ê³¼ ì¶”ì¶œ**: ê° í‚¤ì›Œë“œë³„ ê´€ë ¨ íš¨ê³¼ ì¶”ì¶œ
3. **ì¡°í•© ë¶„ì„**: ê°€ì¥ ì˜ íŒ”ë¦¬ëŠ” ì¡°í•© (ì„±ë¶„ + ì œí˜• + íš¨ê³¼) ë¶„ì„
4. **ë¦¬ë”ë³´ë“œ ì¬êµ¬ì„±**: DB ê¸°ë°˜ ë¦¬ë”ë³´ë“œ ìƒì„±
5. **SNS í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„**: í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„ ë°” ì¶œë ¥
6. **ì‹œê°í™” ë°ì´í„° ì €ì¥**: LLM ì¶œë ¥ì„ DBì— ì €ì¥ â†’ ì§‘ê³„ â†’ ì‹œê°í™”

---

## ğŸ”„ ì „ì²´ ì›Œí¬í”Œë¡œìš°

```
Raw ë°ì´í„° (ì œí’ˆ ì„¤ëª…, ë¦¬ë·°, SNS)
    â†“
[Agent 1] í‚¤ì›Œë“œ ì¶”ì¶œ Agent
    â”œâ”€â†’ ì„±ë¶„ ì¶”ì¶œ
    â”œâ”€â†’ ì œí˜• ì¶”ì¶œ
    â”œâ”€â†’ íš¨ê³¼ ì¶”ì¶œ
    â””â”€â†’ Mood ì¶”ì¶œ
    â†“
[Agent 2] íš¨ê³¼ ë§¤í•‘ Agent
    â””â”€â†’ ê° í‚¤ì›Œë“œë³„ ê´€ë ¨ íš¨ê³¼ ì¶”ì¶œ
    â†“
[Agent 3] ì¡°í•© ë¶„ì„ Agent
    â””â”€â†’ ì„±ë¶„ + ì œí˜• + íš¨ê³¼ ì¡°í•© ë¶„ì„
    â†“
[Agent 4] íŠ¸ë Œë“œ ì§‘ê³„ Agent
    â””â”€â†’ ì¡°í•©ë³„ íŒë§¤ ë­í‚¹ ì§‘ê³„
    â†“
[Agent 5] SNS í”Œë«í¼ ë¶„ì„ Agent
    â””â”€â†’ í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„ ë¶„ì„
    â†“
DB ì €ì¥ (processed_keywords, trends, sns_platform_stats)
    â†“
ì‹œê°í™” (ë¦¬ë”ë³´ë“œ, íŠ¸ë Œë“œ ì°¨íŠ¸, SNS ìˆœìœ„ ë°”)
```

---

## ğŸ“¦ LangChain + LangGraph êµ¬ì¡°

### Node ì •ì˜

```python
# ê° NodeëŠ” íŠ¹ì • Agent ì—­í• 
nodes = {
    "extract_keywords": KeywordExtractorAgent,
    "map_effects": EffectMapperAgent,
    "analyze_combinations": CombinationAnalyzerAgent,
    "aggregate_trends": TrendAggregatorAgent,
    "analyze_sns_platforms": SNSPlatformAnalyzerAgent
}
```

### Edge ì •ì˜

```python
# ë°ì´í„° íë¦„ ì •ì˜
edges = [
    ("extract_keywords", "map_effects"),
    ("map_effects", "analyze_combinations"),
    ("analyze_combinations", "aggregate_trends"),
    ("aggregate_trends", "analyze_sns_platforms")
]
```

---

## ğŸ¤– Agent ìƒì„¸ ì„¤ê³„

### Agent 1: í‚¤ì›Œë“œ ì¶”ì¶œ Agent

**ì…ë ¥**: ì œí’ˆ ì„¤ëª… í…ìŠ¤íŠ¸
**ì¶œë ¥**: 
```json
{
  "ingredients": ["ë ˆí‹°ë†€", "íˆì•Œë£¨ë¡ ì‚°"],
  "formulas": ["ì•°í”Œ", "ì„¸ëŸ¼"],
  "effects": ["ëª¨ê³µ ì¼€ì–´", "ì¥ë²½ ê°•í™”"],
  "mood": ["ë¯¸ë‹ˆì–´ì²˜", "ë§¤íŠ¸ í…ìŠ¤ì²˜"]
}
```

### Agent 2: íš¨ê³¼ ë§¤í•‘ Agent

**ì…ë ¥**: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì„±ë¶„/ì œí˜•/íš¨ê³¼/Mood)
**ì¶œë ¥**: ê° í‚¤ì›Œë“œë³„ ê´€ë ¨ íš¨ê³¼
```json
{
  "ë ˆí‹°ë†€": {
    "effects": ["ëª¨ê³µ ì¼€ì–´", "ê°ì§ˆ ì œê±°", "ì•ˆí‹°ì—ì´ì§•"],
    "frequency": 45
  },
  "ì•°í”Œ": {
    "effects": ["ê³ ë†ì¶• ì „ë‹¬", "ë¹ ë¥¸ í¡ìˆ˜"],
    "frequency": 32
  }
}
```

### Agent 3: ì¡°í•© ë¶„ì„ Agent

**ì…ë ¥**: 
- ì œí’ˆë³„ í‚¤ì›Œë“œ (ì„±ë¶„ + ì œí˜• + íš¨ê³¼)
- ì œí’ˆ ë­í‚¹ ë°ì´í„°
**ì¶œë ¥**: ì¡°í•©ë³„ íŒë§¤ ì„±ê³¼
```json
{
  "combination": "ë ˆí‹°ë†€ + ì•°í”Œ + ëª¨ê³µ ì¼€ì–´",
  "avgRank": 12.5,
  "productCount": 15,
  "totalSales": 125000,
  "synergyScore": 0.92
}
```

### Agent 4: íŠ¸ë Œë“œ ì§‘ê³„ Agent

**ì…ë ¥**: ì¡°í•© ë¶„ì„ ê²°ê³¼
**ì¶œë ¥**: íŠ¸ë Œë“œ ì ìˆ˜ ë° ë¶„ë¥˜
```json
{
  "combination": "ë ˆí‹°ë†€ + ì•°í”Œ + ëª¨ê³µ ì¼€ì–´",
  "score": 98,
  "category": "Actionable",
  "signals": {
    "SNS": 95,
    "Retail": 86,
    "Review": 90
  }
}
```

### Agent 5: SNS í”Œë«í¼ ë¶„ì„ Agent

**ì…ë ¥**: SNS ê²Œì‹œë¬¼ ë°ì´í„°
**ì¶œë ¥**: í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„
```json
{
  "platform": "Instagram",
  "keywords": [
    {"keyword": "ë ˆí‹°ë†€", "value": 95, "change": 12},
    {"keyword": "ì•°í”Œ", "value": 88, "change": 8}
  ]
}
```

---

## ğŸ’¾ DB ì €ì¥ êµ¬ì¡°

### processed_keywords ì»¬ë ‰ì…˜

```javascript
{
  _id: ObjectId,
  keyword: "ë ˆí‹°ë†€",
  keywordType: "ingredient", // ingredient, formula, effect, mood
  sourceType: "product_description", // product_description, review, sns
  sourceId: ObjectId, // ì œí’ˆ ID ë˜ëŠ” ë¦¬ë·° ID
  effects: ["ëª¨ê³µ ì¼€ì–´", "ê°ì§ˆ ì œê±°"], // Agent 2 ì¶œë ¥
  extractedAt: Date,
  processedAt: Date
}
```

### trends ì»¬ë ‰ì…˜

```javascript
{
  _id: ObjectId,
  combination: "ë ˆí‹°ë†€ + ì•°í”Œ + ëª¨ê³µ ì¼€ì–´",
  ingredients: ["ë ˆí‹°ë†€"],
  formulas: ["ì•°í”Œ"],
  effects: ["ëª¨ê³µ ì¼€ì–´"],
  avgRank: 12.5, // Agent 3 ì¶œë ¥
  productCount: 15,
  totalSales: 125000,
  synergyScore: 0.92,
  score: 98, // Agent 4 ì¶œë ¥
  category: "Actionable", // Early, Growing, Actionable
  signals: {
    SNS: 95,
    Retail: 86,
    Review: 90
  },
  calculatedAt: Date
}
```

### sns_platform_stats ì»¬ë ‰ì…˜

```javascript
{
  _id: ObjectId,
  platform: "Instagram", // Instagram, TikTok, YouTube, Amazon, Shopee, Cosme
  country: "usa",
  keywords: [
    {
      keyword: "ë ˆí‹°ë†€",
      value: 95,
      change: 12,
      type: "ingredient"
    }
  ],
  date: Date,
  calculatedAt: Date // Agent 5 ì¶œë ¥
}
```

---

## ğŸ”§ êµ¬í˜„ ì˜ˆì‹œ

### LangGraph ì›Œí¬í”Œë¡œìš° ì •ì˜

```python
from langchain.graph import StateGraph
from langchain.schema import BaseMessage
from typing import TypedDict, List
import json

# State ì •ì˜
class WorkflowState(TypedDict):
    product_descriptions: List[str]
    product_ids: List[str]
    extracted_keywords: dict
    mapped_effects: dict
    combinations: dict
    trends: dict
    sns_stats: dict

# Agent 1: í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords_node(state: WorkflowState) -> WorkflowState:
    # LLM í˜¸ì¶œí•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = {}
    for desc in state["product_descriptions"]:
        result = llm_agent1.extract(desc)
        keywords[state["product_ids"][state["product_descriptions"].index(desc)]] = result
    
    state["extracted_keywords"] = keywords
    return state

# Agent 2: íš¨ê³¼ ë§¤í•‘
def map_effects_node(state: WorkflowState) -> WorkflowState:
    # ê° í‚¤ì›Œë“œë³„ íš¨ê³¼ ì¶”ì¶œ
    effects = {}
    for product_id, keywords in state["extracted_keywords"].items():
        all_keywords = (
            keywords.get("ingredients", []) +
            keywords.get("formulas", []) +
            keywords.get("effects", []) +
            keywords.get("mood", [])
        )
        effects[product_id] = llm_agent2.map_effects(all_keywords)
    
    state["mapped_effects"] = effects
    return state

# Agent 3: ì¡°í•© ë¶„ì„
def analyze_combinations_node(state: WorkflowState) -> WorkflowState:
    # ì¡°í•©ë³„ íŒë§¤ ì„±ê³¼ ë¶„ì„
    combinations = llm_agent3.analyze(
        state["extracted_keywords"],
        state["mapped_effects"],
        db.get_ranking_data()
    )
    
    state["combinations"] = combinations
    return state

# Agent 4: íŠ¸ë Œë“œ ì§‘ê³„
def aggregate_trends_node(state: WorkflowState) -> WorkflowState:
    # íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚° ë° ë¶„ë¥˜
    trends = llm_agent4.aggregate(
        state["combinations"],
        db.get_signal_data()
    )
    
    state["trends"] = trends
    return state

# Agent 5: SNS í”Œë«í¼ ë¶„ì„
def analyze_sns_platforms_node(state: WorkflowState) -> WorkflowState:
    # í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„ ë¶„ì„
    sns_stats = llm_agent5.analyze(
        db.get_sns_data(),
        state["extracted_keywords"]
    )
    
    state["sns_stats"] = sns_stats
    return state

# ì›Œí¬í”Œë¡œìš° êµ¬ì„±
workflow = StateGraph(WorkflowState)
workflow.add_node("extract_keywords", extract_keywords_node)
workflow.add_node("map_effects", map_effects_node)
workflow.add_node("analyze_combinations", analyze_combinations_node)
workflow.add_node("aggregate_trends", aggregate_trends_node)
workflow.add_node("analyze_sns_platforms", analyze_sns_platforms_node)

# Edge ì •ì˜
workflow.set_entry_point("extract_keywords")
workflow.add_edge("extract_keywords", "map_effects")
workflow.add_edge("map_effects", "analyze_combinations")
workflow.add_edge("analyze_combinations", "aggregate_trends")
workflow.add_edge("aggregate_trends", "analyze_sns_platforms")

# ì»´íŒŒì¼
app = workflow.compile()
```

---

## ğŸ“Š ì‹¤í–‰ ë° DB ì €ì¥

```python
# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
initial_state = {
    "product_descriptions": product_descriptions,
    "product_ids": product_ids,
    "extracted_keywords": {},
    "mapped_effects": {},
    "combinations": {},
    "trends": {},
    "sns_stats": {}
}

final_state = app.invoke(initial_state)

# DB ì €ì¥
save_to_db(final_state)
```

---

## ğŸ¨ ì‹œê°í™” ë°ì´í„° ìƒì„±

```python
def save_to_db(state: WorkflowState):
    # 1. processed_keywords ì €ì¥
    for product_id, keywords in state["extracted_keywords"].items():
        for keyword_type, keyword_list in keywords.items():
            for keyword in keyword_list:
                effects = state["mapped_effects"].get(product_id, {}).get(keyword, [])
                db.processed_keywords.insert_one({
                    "keyword": keyword,
                    "keywordType": keyword_type,
                    "sourceType": "product_description",
                    "sourceId": product_id,
                    "effects": effects,
                    "extractedAt": datetime.now()
                })
    
    # 2. trends ì €ì¥
    for combination, data in state["trends"].items():
        db.trends.insert_one({
            "combination": combination,
            "ingredients": data["ingredients"],
            "formulas": data["formulas"],
            "effects": data["effects"],
            "avgRank": data["avgRank"],
            "productCount": data["productCount"],
            "score": data["score"],
            "category": data["category"],
            "signals": data["signals"],
            "calculatedAt": datetime.now()
        })
    
    # 3. sns_platform_stats ì €ì¥
    for platform, stats in state["sns_stats"].items():
        db.sns_platform_stats.insert_one({
            "platform": platform,
            "country": "usa",
            "keywords": stats["keywords"],
            "date": datetime.now(),
            "calculatedAt": datetime.now()
        })
```

---

## ğŸ”„ ì£¼ê¸°ì  ì‹¤í–‰ (8ì£¼ ë°ì´í„° ê¸°ì¤€)

```python
# ë§¤ì£¼ ì›”ìš”ì¼ ì‹¤í–‰
def weekly_workflow():
    # ìµœê·¼ 8ì£¼ ë°ì´í„° ì¡°íšŒ
    end_date = datetime.now()
    start_date = end_date - timedelta(weeks=8)
    
    # ì œí’ˆ ë°ì´í„° ì¡°íšŒ
    products = db.raw_retail_sales.find({
        "date": {"$gte": start_date, "$lte": end_date}
    })
    
    product_descriptions = [p["description"] for p in products]
    product_ids = [p["productId"] for p in products]
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    initial_state = {
        "product_descriptions": product_descriptions,
        "product_ids": product_ids,
        "extracted_keywords": {},
        "mapped_effects": {},
        "combinations": {},
        "trends": {},
        "sns_stats": {}
    }
    
    final_state = app.invoke(initial_state)
    save_to_db(final_state)
    
    # ë¦¬ë”ë³´ë“œ ì¬ìƒì„±
    regenerate_leaderboard()
```

---

## ğŸ“ˆ ë¦¬ë”ë³´ë“œ ì¬êµ¬ì„±

```python
def regenerate_leaderboard():
    # DBì—ì„œ ì§‘ê³„ëœ ë°ì´í„°ë¡œ ë¦¬ë”ë³´ë“œ ìƒì„±
    trends = db.trends.find().sort("score", -1).limit(100)
    
    leaderboard = {
        "ingredients": [],
        "formulas": [],
        "effects": [],
        "mood": []
    }
    
    for trend in trends:
        # ì„±ë¶„ ë¦¬ë”ë³´ë“œ
        for ingredient in trend["ingredients"]:
            leaderboard["ingredients"].append({
                "keyword": ingredient,
                "score": calculate_ingredient_score(ingredient, trends)
            })
        
        # ì œí˜• ë¦¬ë”ë³´ë“œ
        for formula in trend["formulas"]:
            leaderboard["formulas"].append({
                "keyword": formula,
                "score": calculate_formula_score(formula, trends)
            })
        
        # íš¨ê³¼ ë¦¬ë”ë³´ë“œ
        for effect in trend["effects"]:
            leaderboard["effects"].append({
                "keyword": effect,
                "score": calculate_effect_score(effect, trends)
            })
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    for category in leaderboard:
        leaderboard[category].sort(key=lambda x: x["score"], reverse=True)
        leaderboard[category] = [
            {**item, "rank": idx + 1}
            for idx, item in enumerate(leaderboard[category][:20])
        ]
    
    # DB ì €ì¥
    db.leaderboard.replace_one(
        {"country": "usa", "period": "8weeks"},
        {
            "country": "usa",
            "period": "8weeks",
            "data": leaderboard,
            "updatedAt": datetime.now()
        },
        upsert=True
    )
```

---

## ğŸ¯ SNS í”Œë«í¼ë³„ í‚¤ì›Œë“œ ìˆœìœ„

```python
def get_sns_platform_rankings(country="usa"):
    # DBì—ì„œ í”Œë«í¼ë³„ í†µê³„ ì¡°íšŒ
    platforms = ["Instagram", "TikTok", "YouTube", "Amazon", "Shopee", "Cosme"]
    
    rankings = {}
    for platform in platforms:
        stats = db.sns_platform_stats.find_one({
            "platform": platform,
            "country": country
        }, sort=[("date", -1)])
        
        if stats:
            rankings[platform] = stats["keywords"][:10]  # ìƒìœ„ 10ê°œ
    
    return rankings
```

---

## ğŸ’¡ ìµœì í™” ì „ëµ

1. **ë³‘ë ¬ ì²˜ë¦¬**: ê° ì œí’ˆë³„ í‚¤ì›Œë“œ ì¶”ì¶œì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
2. **ìºì‹±**: ì´ë¯¸ ì²˜ë¦¬ëœ ì œí’ˆì€ ìºì‹œ ì‚¬ìš©
3. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ì œí’ˆì„ í•œ ë²ˆì— ì²˜ë¦¬
4. **ì¦ë¶„ ì—…ë°ì´íŠ¸**: ë³€ê²½ëœ ë°ì´í„°ë§Œ ì¬ì²˜ë¦¬

